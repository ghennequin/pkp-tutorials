{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A model of orientation selectivity in visual cortex\n",
    "\n",
    "In this tutorial, you will build, simulate, and analyse the network model that we discussed in our lecture on primary visual cortex. This model was first invented to explain the emergence of sharp orientation selectivity in V1, despite LGN input to V1 neurons being only weakly tuned.\n",
    "\n",
    "You will begin by exploring Hubel and Wiesel's original \"feedforward model\", investigate its weaknesses, and show how recurrent processing within V1 can overcome these.\n",
    "\n",
    "Take some time now to read the [documentation](https://pkp-neuro.github.io/pkp-tutorials/pkp/Pkp/V1/index.html) of the `V1` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#require \"pkp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open Owl\n",
    "open Gp\n",
    "open Pkp.V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let _ = Pkp.Misc.quiet_owl ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hubel and Wiesel's “feedforward model”\n",
    "\n",
    "Let's take a given V1 neuron, which is selective to a particular orientation. The original “feedforward model” of Hubel and Wiesel explains such selectivity by postulating that the LGN input to this neuron is _already tuned_ to that same orientation (they invoked a putative, careful positioning of the receptive fields of LGN cells that provide input to this V1 neuron).\n",
    "\n",
    "The function `input_from_LGN` models such baseline tuning, given a certain stimulus contrast and orientation. Use it to create an input vector (e.g. 0 radians, contrast of 1.0), which you can visualise using this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let plot_input h =\n",
    "  let fig (module P : Plot) =\n",
    "    P.plot\n",
    "      (L [ angles; h ])\n",
    "      ~style:\"l lc 8 lw 2\"\n",
    "      (angular_axis\n",
    "      @ [ yrange (0., max 1. (1.2 *. Mat.max' h)); ytics (`regular [ 0.; 1. ]) ])\n",
    "  in\n",
    "  Juplot.draw ~size:(300, 200) fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(* your code here *)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine providing such a steady LGN input to our V1 neurons. In each neuron, the steady input gives rise to a steady firing rate, given by `firing_rate_function`. Begin by visualising this input-to-rate transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(* your code here *)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now simulate the network (with `feedforward_prms`) with various inputs and inspect the resulting responses (function `plot_dynamics`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(* your code here *) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that this feedforward network violates “contrast invariance”, which is the experimental observation in V1 that tuning curves have roughly the same width irrespective of stimulus contrast. Do do this, you will need to vary the contrast level, and plot network responses _relative to the peak response_ (which you can do using the `normalise` function). You may use the `plot_steady_states` function to plot multiple steady-state responses (e.g. correponding to different input contrasts) on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(* your code here *)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ben Yishai and Sompolinsky's recurrent V1 model\n",
    "\n",
    "Using `recurrent_prms` instead of `feedforward_prms`, you can simulate the full recurrent model discussed in lectures. Neurons are connected such that neighbouring neurons excite each other, and more distant neurons inhibit each other.\n",
    "\n",
    "Begin by inspecting the response of the model to LGN input. How does it depend on stimulus angle and contrast?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(* your code here *)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the model produces contrast-invariant tuning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(* your code here *)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at time-varying stimuli. Stimulate the recurrent model using an input that arises at $t=0.1$ s, stays on for 0.2 s, and then disappears (you can do this by modulating the contrast as a function of time). How does the network respond?\n",
    "\n",
    "Try again with parameters `{ a = 9.5; b = 16. }` and a peak contrast of `0.1`. What do you see? How about with `{ a = 9.4; b = 16. }` (and a peak contrast of `0.1` again)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(* your code here *)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OCaml 4.07.1+flambda",
   "language": "OCaml",
   "name": "ocaml-jupyter"
  },
  "language_info": {
   "codemirror_mode": "text/x-ocaml",
   "file_extension": ".ml",
   "mimetype": "text/x-ocaml",
   "name": "OCaml",
   "nbconverter_exporter": null,
   "pygments_lexer": "OCaml",
   "version": "4.07.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
