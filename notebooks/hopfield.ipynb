{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hopfield network (autoassociative memory)\n",
    "\n",
    "\n",
    "In this tutorial, you will simulate the autoassociative memory network invented by J Hopfield (1982) and try to figure out how many memories a network of size N can successfully store and retrieve.\n",
    "\n",
    "Please take a minute to get familiar with the [documentation](https://pkp-neuro.github.io/pkp-tutorials/pkp/Pkp/Hopfield/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    ";;\n",
    "#require \"pkp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "open Owl\n",
    "\n",
    "open Gp\n",
    "\n",
    "open Pkp.Hopfield\n",
    "\n",
    "open Pkp.Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "- : unit = ()\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let _ = Pkp.Misc.quiet_owl ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started by examining the autoassociate memory behaviour of this network in simple cases. At first, we will consider a network of size `n=200` neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let n = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a few random activity patterns, which will be stored later through modifications of the recurrent connectivity of the network: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let k = 10 (* number of memories to be stored *)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let patterns = Array.init k (fun _ -> random_pattern n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check these out (here, I'm plotting the first pattern, but look at a few others, too!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let _ = plot_pattern patterns.(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Hopfield network is essentially defined by its connectivity matrix, which is built from the set of activity patterns that are meant to be “memorised”. So let's build such a connectivity using our 10 patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let w = connectivity patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test whether these patterns have been successfully “memorised”, in the sense that if we cue the network using an incomplete (or corrupted) memory state, its dynamics will converge back to that state. “Cueing” the network means initialising it at time `t=0` in a particular activity state. Below, I chose a cue (initial state) that is a corrupted version of the first pattern we stored in the connectivity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let cue = corrupt ~fraction:0.1 patterns.(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visually compare the cue and the original pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let _ = compare_patterns (cue, \"corrupted\") (patterns.(0), \"original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let recalled = recall ~compare_with:patterns.(0) ~t_max:10. w cue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take some time to investigate the effect of the two free parameters we have here: the size `n` of the network (the larger, the longer the simulations, so don't go crazy here :) 1000 max) and the cue corruption level (the `~fraction` parameter in function `corrupt`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, set `n=200` and `k=10`, and write code to determine how many of the 10 stored patterns can be successfully recalled (for a corruption level of `~fraction:0.1`). You might want to use `Array.map (fun p -> ....) patterns` to iterate all of your `k` patterns, and for each:\n",
    "1. corrupt the pattern to form a cue\n",
    "2. run the recall dynamics from that cue\n",
    "3. compare the final state to the original pattern (function `are_equal`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(* your code here *)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try again for `k=20` (and `n=200` as before). Run the experiment several times (including choosing new patterns each time). What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(* your code here *)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, write a function that takes an `n` and a `k`, and estimate the probability of successful recall. You will need to average over multiple independent experiments in order to get reliable estimates. This can be done using `average_over` ([documented here](https://pkp-neuro.github.io/pkp-tutorials/pkp/Pkp/Misc/index.html#val-average_over):\n",
    "\n",
    "```ocaml\n",
    "(* a dummy function that returns a \n",
    "   random number between 0 and 1, \n",
    "   just for illustrating `average_over` *)\n",
    "let f () = Random.float 1. \n",
    "\n",
    "let result = average_over 100 f\n",
    "```\n",
    "\n",
    "(and there's a `~display` optional parameter if you want to display progress in the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(* your code here *)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, write a function that takes a network size `n`, and uses the function you've defined just above in order to estimate the maximum `k` that still gives you a probability of correct memory recall above 90%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(* your code here *)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot this function! This is the so-called network capacity, as a function of `n`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OCaml 4.07.1+flambda",
   "language": "OCaml",
   "name": "ocaml-jupyter"
  },
  "language_info": {
   "codemirror_mode": "text/x-ocaml",
   "file_extension": ".ml",
   "mimetype": "text/x-ocaml",
   "name": "OCaml",
   "nbconverter_exporter": null,
   "pygments_lexer": "OCaml",
   "version": "4.07.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
